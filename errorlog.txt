python /home/endodl/Wade-Archives/PolypsSet/train_rtdetr_polyps.py

=== System Information ===
Python version: 3.10.16 (main, Dec  4 2024, 08:53:37) [GCC 9.4.0]
PyTorch version: 2.6.0+cu124
CUDA version (torch): 12.4

=== CUDA Information ===
CUDA device: NVIDIA GeForce RTX 3090
CUDA device capability: (8, 6)
Current CUDA device: 0

Using device: cuda:0

=== Loading Model ===
/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Could not load the custom kernel for multi-scale deformable attention: Error building extension 'MultiScaleDeformableAttention': [1/2] /usr/local/cuda-10.2/bin/nvcc --generate-dependencies-with-compile --dependency-output ms_deform_attn_cuda.cuda.o.d -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/kernels/deformable_detr -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include/TH -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda-10.2/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -std=c++17 -c /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu -o ms_deform_attn_cuda.cuda.o 
FAILED: ms_deform_attn_cuda.cuda.o 
/usr/local/cuda-10.2/bin/nvcc --generate-dependencies-with-compile --dependency-output ms_deform_attn_cuda.cuda.o.d -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/kernels/deformable_detr -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include/TH -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda-10.2/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -std=c++17 -c /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu -o ms_deform_attn_cuda.cuda.o 
/bin/sh: 1: /usr/local/cuda-10.2/bin/nvcc: not found
ninja: build stopped: subcommand failed.

Could not load the custom kernel for multi-scale deformable attention: /home/endodl/.cache/torch_extensions/py310_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory
Could not load the custom kernel for multi-scale deformable attention: /home/endodl/.cache/torch_extensions/py310_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory
Could not load the custom kernel for multi-scale deformable attention: /home/endodl/.cache/torch_extensions/py310_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory
Could not load the custom kernel for multi-scale deformable attention: /home/endodl/.cache/torch_extensions/py310_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory
Could not load the custom kernel for multi-scale deformable attention: /home/endodl/.cache/torch_extensions/py310_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.

Creating datasets...
Total annotations: 27048
Total images in annotations: 27048
Number of images with annotations: 27048
Train dataset size: 27048
Total annotations: 4584
Total images in annotations: 4584
Number of images with annotations: 4584
Val dataset size: 4584
/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/training_args.py:1576: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead
  warnings.warn(

Starting training...
{'loss': 240.9774, 'grad_norm': 1890.8160400390625, 'learning_rate': 0.00019999526627218937, 'epoch': 0.01}                                                               
{'loss': 161.7028, 'grad_norm': 2934.188720703125, 'learning_rate': 0.0001999715976331361, 'epoch': 0.01}                                                                 
{'loss': 142.1433, 'grad_norm': 1632.799560546875, 'learning_rate': 0.00019994792899408285, 'epoch': 0.02}                                                                
{'loss': 119.2167, 'grad_norm': 689.2517700195312, 'learning_rate': 0.00019992426035502961, 'epoch': 0.02}                                                                
{'loss': 109.5932, 'grad_norm': 416.5885009765625, 'learning_rate': 0.00019990059171597635, 'epoch': 0.03}                                                                
{'loss': 108.7648, 'grad_norm': 414.0249328613281, 'learning_rate': 0.0001998769230769231, 'epoch': 0.04}                                                                 
{'loss': 106.3387, 'grad_norm': 201.47401428222656, 'learning_rate': 0.00019985325443786983, 'epoch': 0.04}                                                               
{'loss': 99.9387, 'grad_norm': 208.73304748535156, 'learning_rate': 0.0001998295857988166, 'epoch': 0.05}                                                                 
{'loss': 98.432, 'grad_norm': 200.48130798339844, 'learning_rate': 0.00019980591715976334, 'epoch': 0.05}                                                                 
{'loss': 94.85, 'grad_norm': 263.0897216796875, 'learning_rate': 0.00019978224852071005, 'epoch': 0.06}                                                                   
{'loss': 88.765, 'grad_norm': 251.35792541503906, 'learning_rate': 0.0001997585798816568, 'epoch': 0.07}                                                                  
  0%|‚ñè                                                                                                                             | 119/84500 [01:10<13:41:16,  1.71it/s]Traceback (most recent call last):
  File "/home/endodl/Wade-Archives/PolypsSet/train_rtdetr_polyps.py", line 237, in <module>
    main()
  File "/home/endodl/Wade-Archives/PolypsSet/train_rtdetr_polyps.py", line 234, in main
    trainer.train()
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2184, in train
    return inner_training_loop(
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2490, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 3598, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 3659, in compute_loss
    outputs = model(**inputs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py", line 2076, in forward
    loss, loss_dict, auxiliary_outputs = self.loss_function(
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/loss/loss_rt_detr.py", line 468, in RTDetrForObjectDetectionLoss
    loss_dict = criterion(outputs_loss, labels)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/loss/loss_rt_detr.py", line 384, in forward
    indices = self.matcher(outputs_without_aux, targets)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/loss/loss_rt_detr.py", line 116, in forward
    giou_cost = -generalized_box_iou(center_to_corners_format(out_bbox), center_to_corners_format(target_bbox))
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/loss/loss_for_object_detection.py", line 418, in generalized_box_iou
    raise ValueError(f"boxes1 must be in [x0, y0, x1, y1] (corner) format, but got {boxes1}")
ValueError: boxes1 must be in [x0, y0, x1, y1] (corner) format, but got tensor([[nan, nan, nan, nan],
        [nan, nan, nan, nan],
        [nan, nan, nan, nan],
        ...,
        [nan, nan, nan, nan],
        [nan, nan, nan, nan],
        [nan, nan, nan, nan]], device='cuda:0')
Exception in thread Thread-2 (_pin_memory_loop):
Traceback (most recent call last):
  File "/usr/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.10/threading.py", line 953, in run
    self._target(*self._args, **self._kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 59, in _pin_memory_loop
    do_one_step()
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py", line 35, in do_one_step
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/usr/lib/python3.10/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/multiprocessing/reductions.py", line 541, in rebuild_storage_fd
    fd = df.detach()
  File "/usr/lib/python3.10/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/usr/lib/python3.10/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 508, in Client
    answer_challenge(c, authkey)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 757, in answer_challenge
    response = connection.recv_bytes(256)        # reject large message
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 414, in _recv_bytes
    buf = self._recv(4)
  File "/usr/lib/python3.10/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
  0%|‚ñè                                                                                                                             | 119/84500 [01:10<13:57:16,  1.68it/s]
(.venv) endodl@htic:~/Wade-Archives$ 
