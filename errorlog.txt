 python /home/endodl/Wade-Archives/PolypsSet/train_rtdetr_polyps.py

=== System Information ===
Python version: 3.10.16 (main, Dec  4 2024, 08:53:37) [GCC 9.4.0]
PyTorch version: 2.6.0+cu124
CUDA version (torch): 12.4

=== CUDA Information ===
CUDA device: NVIDIA GeForce RTX 3090
CUDA device capability: (8, 6)
Current CUDA device: 0

Using device: cuda:0

=== Loading Model ===
/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/utils/cpp_extension.py:2059: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].
  warnings.warn(
Could not load the custom kernel for multi-scale deformable attention: Error building extension 'MultiScaleDeformableAttention': [1/2] /usr/local/cuda-10.2/bin/nvcc --generate-dependencies-with-compile --dependency-output ms_deform_attn_cuda.cuda.o.d -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/kernels/deformable_detr -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include/TH -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda-10.2/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -std=c++17 -c /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu -o ms_deform_attn_cuda.cuda.o 
FAILED: ms_deform_attn_cuda.cuda.o 
/usr/local/cuda-10.2/bin/nvcc --generate-dependencies-with-compile --dependency-output ms_deform_attn_cuda.cuda.o.d -DTORCH_EXTENSION_NAME=MultiScaleDeformableAttention -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -I/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/kernels/deformable_detr -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include/TH -isystem /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda-10.2/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -DCUDA_HAS_FP16=1 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ -std=c++17 -c /home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/kernels/deformable_detr/cuda/ms_deform_attn_cuda.cu -o ms_deform_attn_cuda.cuda.o 
/bin/sh: 1: /usr/local/cuda-10.2/bin/nvcc: not found
ninja: build stopped: subcommand failed.

Could not load the custom kernel for multi-scale deformable attention: /home/endodl/.cache/torch_extensions/py310_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory
Could not load the custom kernel for multi-scale deformable attention: /home/endodl/.cache/torch_extensions/py310_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory
Could not load the custom kernel for multi-scale deformable attention: /home/endodl/.cache/torch_extensions/py310_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory
Could not load the custom kernel for multi-scale deformable attention: /home/endodl/.cache/torch_extensions/py310_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory
Could not load the custom kernel for multi-scale deformable attention: /home/endodl/.cache/torch_extensions/py310_cu124/MultiScaleDeformableAttention/MultiScaleDeformableAttention.so: cannot open shared object file: No such file or directory
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.

Creating datasets...
Total annotations: 27048
Total images in annotations: 27048
Number of images with annotations: 27048
Train dataset size: 27048
Total annotations: 4584
Total images in annotations: 4584
Number of images with annotations: 4584
Val dataset size: 0
Skipped 4584 images due to missing files
First 5 missing image paths:
  Tried: ['/home/endodl/Wade-Archives/PolypsSet/val2019/Image/Image/10/124.jpg', '/home/endodl/Wade-Archives/PolypsSet/val2019/Image/Image/124.jpg', '/home/endodl/Wade-Archives/PolypsSet/val2019/Image/124.jpg']
  Tried: ['/home/endodl/Wade-Archives/PolypsSet/val2019/Image/Image/10/12.jpg', '/home/endodl/Wade-Archives/PolypsSet/val2019/Image/Image/12.jpg', '/home/endodl/Wade-Archives/PolypsSet/val2019/Image/12.jpg']
  Tried: ['/home/endodl/Wade-Archives/PolypsSet/val2019/Image/Image/10/107.jpg', '/home/endodl/Wade-Archives/PolypsSet/val2019/Image/Image/107.jpg', '/home/endodl/Wade-Archives/PolypsSet/val2019/Image/107.jpg']
  Tried: ['/home/endodl/Wade-Archives/PolypsSet/val2019/Image/Image/10/154.jpg', '/home/endodl/Wade-Archives/PolypsSet/val2019/Image/Image/154.jpg', '/home/endodl/Wade-Archives/PolypsSet/val2019/Image/154.jpg']
  Tried: ['/home/endodl/Wade-Archives/PolypsSet/val2019/Image/Image/10/60.jpg', '/home/endodl/Wade-Archives/PolypsSet/val2019/Image/Image/60.jpg', '/home/endodl/Wade-Archives/PolypsSet/val2019/Image/60.jpg']
/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/training_args.py:1576: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead
  warnings.warn(

Starting training...
{'loss': 243.0698, 'grad_norm': 1433.3834228515625, 'learning_rate': 0.00019992899408284026, 'epoch': 0.01}                                                               
{'loss': 152.3607, 'grad_norm': 1164.594970703125, 'learning_rate': 0.00019973964497041423, 'epoch': 0.02}                                                                
{'loss': 124.0824, 'grad_norm': 859.6761474609375, 'learning_rate': 0.00019950295857988165, 'epoch': 0.04}                                                                
{'loss': 113.8345, 'grad_norm': 618.4326171875, 'learning_rate': 0.00019926627218934913, 'epoch': 0.05}                                                                   
{'loss': 106.5883, 'grad_norm': 638.6058959960938, 'learning_rate': 0.00019902958579881658, 'epoch': 0.06}                                                                
{'loss': 102.6428, 'grad_norm': 411.2390441894531, 'learning_rate': 0.00019879289940828403, 'epoch': 0.07}                                                                
{'loss': 98.079, 'grad_norm': 545.8130493164062, 'learning_rate': 0.00019855621301775148, 'epoch': 0.08}                                                                  
{'loss': 97.0607, 'grad_norm': 174.49676513671875, 'learning_rate': 0.00019831952662721896, 'epoch': 0.09}                                                                
{'loss': 91.079, 'grad_norm': 162.3531494140625, 'learning_rate': 0.00019808284023668639, 'epoch': 0.11}                                                                  
{'loss': 84.7684, 'grad_norm': 203.6673583984375, 'learning_rate': 0.00019784615384615386, 'epoch': 0.12}                                                                 
{'loss': 84.9602, 'grad_norm': 201.7064666748047, 'learning_rate': 0.00019760946745562132, 'epoch': 0.13}                                                                 
{'loss': 80.2774, 'grad_norm': 165.24551391601562, 'learning_rate': 0.00019737278106508877, 'epoch': 0.14}                                                                
{'loss': 74.5513, 'grad_norm': 125.1448745727539, 'learning_rate': 0.00019713609467455622, 'epoch': 0.15}                                                                 
{'loss': 75.7035, 'grad_norm': 272.3617858886719, 'learning_rate': 0.00019689940828402367, 'epoch': 0.17}                                                                 
{'loss': 71.1359, 'grad_norm': 114.69764709472656, 'learning_rate': 0.00019666272189349112, 'epoch': 0.18}                                                                
{'loss': 72.5143, 'grad_norm': 296.09765625, 'learning_rate': 0.0001964260355029586, 'epoch': 0.19}                                                                       
{'loss': 70.3052, 'grad_norm': 222.25357055664062, 'learning_rate': 0.00019618934911242602, 'epoch': 0.2}                                                                 
{'loss': 71.4461, 'grad_norm': 121.35287475585938, 'learning_rate': 0.0001959526627218935, 'epoch': 0.21}                                                                 
{'loss': 65.7218, 'grad_norm': 258.3321228027344, 'learning_rate': 0.00019571597633136095, 'epoch': 0.22}                                                                 
{'loss': 66.8382, 'grad_norm': 266.67718505859375, 'learning_rate': 0.0001954792899408284, 'epoch': 0.24}                                                                 
  2%|â–ˆâ–ˆâ–ˆ                                                                                                                             | 206/8450 [03:30<2:40:44,  1.17s/it]Traceback (most recent call last):
  File "/home/endodl/Wade-Archives/PolypsSet/train_rtdetr_polyps.py", line 227, in <module>
    main()
  File "/home/endodl/Wade-Archives/PolypsSet/train_rtdetr_polyps.py", line 224, in main
    trainer.train()
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2184, in train
    return inner_training_loop(
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 2490, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 3598, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/trainer.py", line 3659, in compute_loss
    outputs = model(**inputs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py", line 819, in forward
    return model_forward(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/accelerate/utils/operations.py", line 807, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/models/rt_detr_v2/modeling_rt_detr_v2.py", line 2076, in forward
    loss, loss_dict, auxiliary_outputs = self.loss_function(
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/loss/loss_rt_detr.py", line 468, in RTDetrForObjectDetectionLoss
    loss_dict = criterion(outputs_loss, labels)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/loss/loss_rt_detr.py", line 384, in forward
    indices = self.matcher(outputs_without_aux, targets)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/loss/loss_rt_detr.py", line 116, in forward
    giou_cost = -generalized_box_iou(center_to_corners_format(out_bbox), center_to_corners_format(target_bbox))
  File "/home/endodl/Wade-Archives/.venv/lib/python3.10/site-packages/transformers/loss/loss_for_object_detection.py", line 418, in generalized_box_iou
    raise ValueError(f"boxes1 must be in [x0, y0, x1, y1] (corner) format, but got {boxes1}")
ValueError: boxes1 must be in [x0, y0, x1, y1] (corner) format, but got tensor([[nan, nan, nan, nan],
        [nan, nan, nan, nan],
        [nan, nan, nan, nan],
        ...,
        [nan, nan, nan, nan],
        [nan, nan, nan, nan],
        [nan, nan, nan, nan]], device='cuda:0')
Exception in thread Thread-2 (_pin_memory_loop):
Traceback (most recent call last):
  File "/usr/lib/python3.10/threading.py", line 1016, in _bootstrap_inner
  2%|â–ˆâ–ˆâ–ˆ                                                                                                                             | 206/8450 [03:35<2:23:50,  1.05s/it]
(.venv) endodl@htic:~/Wade-Archives$ 
